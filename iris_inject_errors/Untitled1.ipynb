{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import error_inject_layer\n",
    "import error_inject_optimizer\n",
    "from tensorflow.python.util import deprecation\n",
    "\n",
    "# smash warnings at beginning\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_features_vector(features, labels):\n",
    "  \"\"\"Pack the features into a single array.\"\"\"\n",
    "  features = tf.stack(list(features.values()), axis=1)\n",
    "  return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab iris dataset from cloud\n",
    "# train_dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n",
    "# train_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(train_dataset_url),\n",
    "#                                            origin=train_dataset_url)\n",
    "# test_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\"\n",
    "# test_fp = tf.keras.utils.get_file(fname=os.path.basename(test_url),\n",
    "#                                   origin=test_url)\n",
    "# print(\"Local copy of the dataset file: {}\".format(train_dataset_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_fp = \"/home/derek/.keras/datasets/iris_training.csv\"\n",
    "\n",
    "test_fp = \"/home/derek/.keras/datasets/iris_test.csv\"\n",
    "\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "feature_names = column_names[:-1]\n",
    "label_name = column_names[-1]\n",
    "class_names = ['Iris setosa', 'Iris versicolor', 'Iris virginica']\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    train_dataset_fp,\n",
    "    batch_size,\n",
    "    column_names=column_names,\n",
    "    label_name=label_name,\n",
    "    num_epochs=1)\n",
    "\n",
    "test_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    test_fp,\n",
    "    batch_size,\n",
    "    column_names=column_names,\n",
    "    label_name='species',\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DATASET INFO:\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>\n",
      "Features: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "Label: species\n",
      "FEATURES:\n",
      "OrderedDict([('sepal_length', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([4.4, 6.2, 5.9, 6. , 6. , 5. , 4.6, 5.1, 6.4, 4.6, 4.8, 5.5, 5.7,\n",
      "       7.7, 4.7, 4.9, 6.5, 5.1, 5.1, 4.4, 6.3, 7.7, 4.9, 5.6, 5.5, 6.9,\n",
      "       6.1, 5.8, 5. , 7.4, 4.9, 5.6], dtype=float32)>), ('sepal_width', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([3.2, 3.4, 3.2, 2.7, 3. , 3.5, 3.6, 3.8, 3.2, 3.4, 3. , 2.6, 4.4,\n",
      "       3.8, 3.2, 3.1, 3. , 3.8, 3.5, 2.9, 2.5, 3. , 2.5, 2.9, 2.4, 3.1,\n",
      "       2.9, 2.7, 3.2, 2.8, 3.1, 2.5], dtype=float32)>), ('petal_length', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([1.3, 5.4, 4.8, 5.1, 4.8, 1.6, 1. , 1.6, 5.3, 1.4, 1.4, 4.4, 1.5,\n",
      "       6.7, 1.3, 1.5, 5.5, 1.5, 1.4, 1.4, 5. , 6.1, 4.5, 3.6, 3.8, 5.1,\n",
      "       4.7, 5.1, 1.2, 6.1, 1.5, 3.9], dtype=float32)>), ('petal_width', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([0.2, 2.3, 1.8, 1.6, 1.8, 0.6, 0.2, 0.2, 2.3, 0.3, 0.3, 1.2, 0.4,\n",
      "       2.2, 0.2, 0.1, 1.8, 0.3, 0.3, 0.2, 1.9, 2.3, 1.7, 1.3, 1.1, 2.3,\n",
      "       1.4, 1.9, 0.2, 1.9, 0.1, 1.1], dtype=float32)>)])\n",
      "4\n",
      "LABELS:\n",
      "tf.Tensor([0 2 1 1 2 0 0 0 2 0 0 1 0 2 0 0 2 0 0 0 2 2 2 1 1 2 1 2 0 2 0 1], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#print dataset info\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "print(\"DATASET INFO:\")\n",
    "print(type(train_dataset))\n",
    "print(\"Features: {}\".format(feature_names))\n",
    "print(\"Label: {}\".format(label_name))\n",
    "\n",
    "# This gets the next batch of data, randomly pulled from the training dataset\n",
    "features, labels = next(iter(train_dataset))\n",
    "print(\"FEATURES:\")\n",
    "print(features)\n",
    "print(len(features))\n",
    "print(\"LABELS:\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates map dataset\n",
    "test_dataset = test_dataset.map(pack_features_vector)\n",
    "train_dataset = train_dataset.map(pack_features_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES, FIRST FIVE:\n",
      "tf.Tensor(\n",
      "[[4.7 3.2 1.3 0.2]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [5.  3.3 1.4 0.2]], shape=(5, 4), dtype=float32)\n",
      "labels\n",
      "tf.Tensor([0 2 2 2 0], shape=(5,), dtype=int32)\n",
      "<MapDataset shapes: ((None, 4), (None,)), types: (tf.float32, tf.int32)>\n",
      "features type:  <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "features data type <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor([4.7 3.2 1.3 0.2], shape=(4,), dtype=float32)\n",
      "tf.Tensor(4.7, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "features, labels = next(iter(train_dataset))\n",
    "print(\"FEATURES, FIRST FIVE:\")\n",
    "print(features[:5])\n",
    "print(\"labels\")\n",
    "print(labels[:5])\n",
    "print(train_dataset)\n",
    "\n",
    "\n",
    "# note, difficult to convert tensor to float and back again\n",
    "print(\"features type: \", type(features))\n",
    "print(\"features data type\", type(features[0]))\n",
    "print(features[0])\n",
    "fl1 = features[0][0]\n",
    "print(fl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "INFERENCE\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),\n",
    "  error_inject_layer.DenseErrorLayer(5, activation=tf.nn.relu, error_rate=0.9),  # input shape required\n",
    "  # error_inject_layer.DenseErrorLayer(6, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(3)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFERENCE\n",
      "\n",
      "\n",
      "\n",
      "PREDICTIONS\n",
      "tf.Tensor(\n",
      "[[ 0.11817942  0.6226523   0.23269494]\n",
      " [ 0.14466292  0.4346968   0.19464624]\n",
      " [-0.07873648 -0.13030834 -0.0998444 ]\n",
      " [ 0.29100406  0.4452667   0.286919  ]\n",
      " [ 0.11831926  0.6268151   0.23369294]], shape=(5, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "predictions = model(features)\n",
    "print(\"\\n\\n\")\n",
    "print(\"PREDICTIONS\")\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.26472938 0.43842164 0.296849  ]\n",
      " [0.29518324 0.39450434 0.31031242]\n",
      " [0.34143108 0.32426918 0.3342997 ]\n",
      " [0.3161835  0.36892205 0.3148945 ]\n",
      " [0.26419517 0.43930057 0.29650432]], shape=(5, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# convert to probability\n",
    "tf.nn.softmax(predictions[:5])\n",
    "print(tf.nn.softmax(predictions[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1]\n",
      "    Labels: [0 2 2 2 0 0 2 2 0 0 0 2 0 2 0 1 2 2 0 1 2 0 2 1 0 0 1 0 2 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "# predict class \n",
    "print(\"Prediction: {}\".format(tf.argmax(predictions, axis=1)))\n",
    "print(\"    Labels: {}\".format(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Y:\n",
      "tf.Tensor([0 2 2 2 0 0 2 2 0 0 0 2 0 2 0 1 2 2 0 1 2 0 2 1 0 0 1 0 2 1 0 2], shape=(32,), dtype=int32)\n",
      "Y_HAT:\n",
      "tf.Tensor(\n",
      "[[ 0.11817942  0.6226523   0.23269494]\n",
      " [ 0.14466292  0.4346968   0.19464624]\n",
      " [-0.07873648 -0.13030834 -0.0998444 ]\n",
      " [ 0.29100406  0.4452667   0.286919  ]\n",
      " [ 0.11831926  0.6268151   0.23369294]\n",
      " [ 0.08580699  0.5047006   0.1800504 ]\n",
      " [ 0.18326971  0.36994857  0.19973697]\n",
      " [ 0.22022462  0.82393396  0.34404644]\n",
      " [ 0.1104206   0.6135557   0.22412163]\n",
      " [ 0.07472987  0.44545847  0.15805395]\n",
      " [ 0.10516592  0.5908983   0.21483567]\n",
      " [ 0.2499798   0.4700879   0.27239516]\n",
      " [ 0.1367069   0.72852224  0.27091655]\n",
      " [ 0.03392694  0.3597755   0.10498507]\n",
      " [ 0.19871688  0.9721219   0.3754833 ]\n",
      " [ 0.15604827  0.5681984   0.23907171]\n",
      " [ 0.2228446   0.53584814  0.26953667]\n",
      " [ 0.11130904  0.21752153  0.1147559 ]\n",
      " [ 0.15104382  0.79873264  0.29802236]\n",
      " [ 0.12165301  0.65531754  0.24256419]\n",
      " [ 0.12778655  0.02030786  0.07156854]\n",
      " [ 0.13614795  0.6886275   0.26202223]\n",
      " [ 0.03449444  0.3132106   0.09564999]\n",
      " [ 0.09034958  0.5183354   0.18498221]\n",
      " [ 0.15887503  0.85346943  0.31628457]\n",
      " [ 0.13810359  0.68939507  0.26386145]\n",
      " [ 0.04944739  0.37564933  0.12164494]\n",
      " [ 0.12480475  0.6854223   0.25161728]\n",
      " [ 0.11018417  0.6555909   0.2327852 ]\n",
      " [ 0.0647832   0.42618352  0.14545724]\n",
      " [ 0.13939637  0.7199752   0.27142045]\n",
      " [ 0.17253634  0.3853954   0.19961381]], shape=(32, 3), dtype=float32)\n",
      "Loss test: 1.2011511325836182\n"
     ]
    }
   ],
   "source": [
    "# define loss function\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def loss(model, x, y):\n",
    "  # print(\"call\")\n",
    "  y_hat = model(x, training=True)\n",
    "  print(\"Y:\")\n",
    "  print(y)\n",
    "  print(\"Y_HAT:\")\n",
    "  print(y_hat)\n",
    "\n",
    "  return loss_object(y_true=y, y_pred=y_hat)\n",
    "\n",
    "l = loss(model, features, labels)\n",
    "print(\"Loss test: {}\".format(l))\n",
    "\n",
    "# define gradient\n",
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets)\n",
    "  return loss_value, tape.gradient(loss_value, model.trainable_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Y:\n",
      "tf.Tensor([0 2 2 2 0 0 2 2 0 0 0 2 0 2 0 1 2 2 0 1 2 0 2 1 0 0 1 0 2 1 0 2], shape=(32,), dtype=int32)\n",
      "Y_HAT:\n",
      "tf.Tensor(\n",
      "[[ 0.11817942  0.6226523   0.23269494]\n",
      " [ 0.14466292  0.4346968   0.19464624]\n",
      " [-0.07873648 -0.13030834 -0.0998444 ]\n",
      " [ 0.29100406  0.4452667   0.286919  ]\n",
      " [ 0.11831926  0.6268151   0.23369294]\n",
      " [ 0.08580699  0.5047006   0.1800504 ]\n",
      " [ 0.18326971  0.36994857  0.19973697]\n",
      " [ 0.22022462  0.82393396  0.34404644]\n",
      " [ 0.1104206   0.6135557   0.22412163]\n",
      " [ 0.07472987  0.44545847  0.15805395]\n",
      " [ 0.10516592  0.5908983   0.21483567]\n",
      " [ 0.2499798   0.4700879   0.27239516]\n",
      " [ 0.1367069   0.72852224  0.27091655]\n",
      " [ 0.03392694  0.3597755   0.10498507]\n",
      " [ 0.19871688  0.9721219   0.3754833 ]\n",
      " [ 0.15604827  0.5681984   0.23907171]\n",
      " [ 0.2228446   0.53584814  0.26953667]\n",
      " [ 0.11130904  0.21752153  0.1147559 ]\n",
      " [ 0.15104382  0.79873264  0.29802236]\n",
      " [ 0.12165301  0.65531754  0.24256419]\n",
      " [ 0.12778655  0.02030786  0.07156854]\n",
      " [ 0.13614795  0.6886275   0.26202223]\n",
      " [ 0.03449444  0.3132106   0.09564999]\n",
      " [ 0.09034958  0.5183354   0.18498221]\n",
      " [ 0.15887503  0.85346943  0.31628457]\n",
      " [ 0.13810359  0.68939507  0.26386145]\n",
      " [ 0.04944739  0.37564933  0.12164494]\n",
      " [ 0.12480475  0.6854223   0.25161728]\n",
      " [ 0.11018417  0.6555909   0.2327852 ]\n",
      " [ 0.0647832   0.42618352  0.14545724]\n",
      " [ 0.13939637  0.7199752   0.27142045]\n",
      " [ 0.17253634  0.3853954   0.19961381]], shape=(32, 3), dtype=float32)\n",
      "Step: 0, Initial Loss: 1.2011511325836182\n",
      "TRAINING\n",
      "Y:\n",
      "tf.Tensor([0 2 2 2 0 0 2 2 0 0 0 2 0 2 0 1 2 2 0 1 2 0 2 1 0 0 1 0 2 1 0 2], shape=(32,), dtype=int32)\n",
      "Y_HAT:\n",
      "tf.Tensor(\n",
      "[[ 0.08666364  0.47994223  0.17681843]\n",
      " [ 0.1224525   0.23711589  0.13176814]\n",
      " [-0.10353094 -0.34410396 -0.16765192]\n",
      " [ 0.26785448  0.23181775  0.22042365]\n",
      " [ 0.08496716  0.47665644  0.17471834]\n",
      " [ 0.04973474  0.34432128  0.11689194]\n",
      " [ 0.1580715   0.14836475  0.1293449 ]\n",
      " [ 0.19135422  0.5701514   0.2621221 ]\n",
      " [ 0.07637922  0.46026632  0.164141  ]\n",
      " [ 0.0426912   0.30191723  0.10179552]\n",
      " [ 0.07144216  0.43908316  0.15545274]\n",
      " [ 0.23229428  0.3031067   0.2203128 ]\n",
      " [ 0.09828785  0.5567396   0.20324391]\n",
      " [-0.01944152  0.12951213  0.01333607]\n",
      " [ 0.16343851  0.8113354   0.3123665 ]\n",
      " [ 0.13433827  0.37424988  0.17686246]\n",
      " [ 0.19805497  0.31631583  0.19963124]\n",
      " [ 0.08780386  0.01114395  0.04923941]\n",
      " [ 0.11377751  0.6307491   0.23217648]\n",
      " [ 0.08034597  0.47267586  0.17009954]\n",
      " [ 0.10679161 -0.17125028  0.01223245]\n",
      " [ 0.1036241   0.54155743  0.20419209]\n",
      " [-0.00855535  0.12571828  0.02129636]\n",
      " [ 0.07048044  0.33979273  0.12773414]\n",
      " [ 0.11933641  0.6754687   0.246586  ]\n",
      " [ 0.10533043  0.5415077   0.20556064]\n",
      " [ 0.00838541  0.19565293  0.05049868]\n",
      " [ 0.08975668  0.5272736   0.18981336]\n",
      " [ 0.05807154  0.4285842   0.1423148 ]\n",
      " [ 0.02516198  0.25187066  0.07652697]\n",
      " [ 0.10446685  0.56266594  0.20955361]\n",
      " [ 0.15120693  0.19514215  0.13928178]], shape=(32, 3), dtype=float32)\n",
      "Step: 1,         Loss: 1.1712309122085571\n"
     ]
    }
   ],
   "source": [
    "optimizer = error_inject_optimizer.SGDErrorInject(learning_rate=0.01)\n",
    "\n",
    "loss_value, grads = grad(model, features, labels)\n",
    "\n",
    "print(\"Step: {}, Initial Loss: {}\".format(optimizer.iterations.numpy(),\n",
    "                                          loss_value.numpy()))\n",
    "\n",
    "optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "print(\"Step: {},         Loss: {}\".format(optimizer.iterations.numpy(),\n",
    "                                          loss(model, features, labels).numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 500\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "  # Training loop - using batches of 32\n",
    "  for x, y in train_dataset:\n",
    "    # Optimize the model\n",
    "    loss_value, grads = grad(model, x, y)\n",
    "    # print(\"LOSS VALUE\")\n",
    "    # print(loss_value)\n",
    "    # print(\"GRADS\")\n",
    "    # print(grads)\n",
    "    print(\"APPY GRADIENTS\")\n",
    "    # print(model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    # Track progress\n",
    "    epoch_loss_avg(loss_value)  # Add current batch loss\n",
    "    # Compare predicted label to actual label\n",
    "    epoch_accuracy(y, model(x))\n",
    "\n",
    "  # End epoch\n",
    "  train_loss_results.append(epoch_loss_avg.result())\n",
    "  train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "  if epoch % 1 == 0:\n",
    "    print(\"RESULTS\")\n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
